{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrize API requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## executivo_federal_dou.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "import boto3\n",
    "from dynamodb_json import json_util as dyjson\n",
    "\n",
    "debug = True\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Same as python's 'range', but for datetime.\n",
    "    NOTE: currently it does not support steps input.\n",
    "    \"\"\"\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + dt.timedelta(n)\n",
    "        \n",
    "def get_artigos_do(data, secao):\n",
    "    \"\"\"\n",
    "    Para uma data (datetime) e uma seção (str) do DOU,\n",
    "    retorna uma lista de jsons com todos os links e outros metadados dos \n",
    "    artigos daquele dia e seção. \n",
    "    \"\"\"\n",
    "    # Hard-coded:\n",
    "    do_date_format = '%d-%m-%Y'\n",
    "    # Transforma data:\n",
    "    data_string = data.strftime(do_date_format)\n",
    "    \n",
    "    # Exemplo de URL: 'http://www.in.gov.br/leiturajornal?data=13-05-2019&secao=do1'\n",
    "    url   = 'http://www.in.gov.br/leiturajornal?data=' + data_string + '&secao=do' + str(secao)\n",
    "\n",
    "    # Specifies number of retries for GET:\n",
    "    session = requests.Session()\n",
    "    session.mount('http://www.in.gov.br', requests.adapters.HTTPAdapter(max_retries=3))\n",
    "    \n",
    "    # Captura a lista de artigos daquele dia e seção:\n",
    "    res   = session.get(url)\n",
    "    tree  = html.fromstring(res.content)\n",
    "    xpath = '//*[@id=\"params\"]/text()'\n",
    "    return json.loads(tree.xpath(xpath)[0])['jsonArray']\n",
    "\n",
    "def fix_filename(urlTitle):\n",
    "    \"\"\"\n",
    "    Change the url 'urlTitle' substring used to acess the DOU article to something \n",
    "    that can be used as part of a filename.    \n",
    "    \"\"\"\n",
    "    fixed = urlTitle.replace('//', '/')\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_remote_config(table_name, key):\n",
    "    \"\"\"\n",
    "    Given a hard-coded table reference in dynamoDB (AWS) (see event), \n",
    "    loads the configuration for the DOU articles' capture.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read json from dynamoDB: \n",
    "    client   = boto3.client('dynamodb')\n",
    "    response = client.get_item(TableName=table_name,Key=key)\n",
    "    response = dyjson.loads(response)\n",
    "    # Get configurations:\n",
    "    config   = response['Item']\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def brasilia_day():\n",
    "    \"\"\"\n",
    "    No matter where the code is ran, return UTC-3 day\n",
    "    (Brasilia local day, no daylight savings)\n",
    "    \"\"\"\n",
    "    return (dt.datetime.utcnow() + dt.timedelta(hours=-3)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def update_config(config, Narticles_in_section):\n",
    "    \"\"\"\n",
    "    Given a config file for capturing DOU articles' URLs and a dict \n",
    "    that states how many articles were found in each requested section\n",
    "    'Narticles_in_section', return an updated config for the next request \n",
    "    try. \n",
    "    \n",
    "    Required config keys:\n",
    "    * end_date    > The articles' date to request the URLs;\n",
    "    * date_format > The format of the date above (e.g. %Y-%m-%d);\n",
    "    * secao       > Current list of sections to request URLs;\n",
    "    * secao_all   > All sections one may want to request (does not update);\n",
    "    * timedelta   > Current implementation requires this to be 0.\n",
    "    * last_extra  > The extra edition number of the last capture.\n",
    "    \"\"\"\n",
    "    \n",
    "    if config['timedelta'] != 0:\n",
    "        raise Exception('current implementation only allows timedelta=0.')\n",
    "    \n",
    "    # Copy config:\n",
    "    config2  = dict(config)\n",
    "    end_date = dt.datetime.strptime(config['end_date'], config['date_format'])\n",
    "            \n",
    "    # If end_date is in the future, keep the same config:\n",
    "    if end_date > brasilia_day():\n",
    "        return config2\n",
    "    \n",
    "    # If end_date is in the past, return next day and all sections:\n",
    "    if end_date < brasilia_day():\n",
    "        config2['secao'] = config['secao_all']\n",
    "        config2['end_date'] = (end_date + dt.timedelta(days=1)).strftime(config['date_format'])\n",
    "        config2['last_extra'] = 0\n",
    "        return config2\n",
    "    \n",
    "    # PRESENT DAY: find out missing sections and set config to that:\n",
    "    # PS: always keep Extra ('e') because it can appear at any time \n",
    "    section_keys = list(filter(lambda k: Narticles_in_section[k] == 0 or k == 'e', Narticles_in_section.keys()))\n",
    "    config2['secao'] = section_keys\n",
    "\n",
    "    # If there are no missing sections, reset sections list and get next day:\n",
    "    if len(section_keys)==0:\n",
    "        config2['end_date'] = (end_date + dt.timedelta(days=1)).strftime(config['date_format'])\n",
    "        config2['secao'] = config['secao_all']\n",
    "        \n",
    "    return config2\n",
    "\n",
    "def get_articles_url(config):\n",
    "    \"\"\"\n",
    "    Get as input a dict 'config' with keys:\n",
    "    \n",
    "    * 'date_format': format of 'end_date' below, e.g. '%Y-%m-%d';\n",
    "    * 'end_date':    last date to search for URLs (one can set to 'now' to get the current day); \n",
    "    * 'secao':       list of DOU sections to scan (1, 2, 3, e and/or 1a, or set to 'all' for '[1,2,3,e]';\n",
    "    * 'timedelta':   number of days from end_date to start URL search (is a negative number);\n",
    "    \n",
    "    and creates a list of DOU articles' URLs to download. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Hard-coded stuff:\n",
    "    url_prefix = 'http://www.in.gov.br/web/dou/-/'\n",
    "    \n",
    "    # Debug message:\n",
    "    if debug:\n",
    "        print(\"Starting get_articles_url with config:\")\n",
    "        print(config)\n",
    "    \n",
    "    # Translate string representing date to datetime:\n",
    "    if debug:\n",
    "        print('Reading date range...')\n",
    "    if config['end_date'] == 'now':\n",
    "        end_date = brasilia_day()\n",
    "    elif config['end_date'] == 'yesterday':\n",
    "        end_date = brasilia_day() + dt.timedelta(days=-1)\n",
    "    else:\n",
    "        end_date = dt.datetime.strptime(config['end_date'], config['date_format'])\n",
    "    # Save it back to config dict:\n",
    "    config['end_date'] = end_date.strftime(config['date_format'])\n",
    "    \n",
    "    timedelta = dt.timedelta(days=config['timedelta'])\n",
    "    \n",
    "    # If end_date is in the future, return empty list and same config\n",
    "    # (wait for the next day):\n",
    "    # PS: this will skip request URLs even for negative timedelta.\n",
    "    if end_date > brasilia_day():\n",
    "        return [], config\n",
    "        \n",
    "    # Translate secao config to a list of strings:\n",
    "    if debug:\n",
    "        print('Reading selected sections...')    \n",
    "    secoes = config['secao']\n",
    "    secoes = [1, 2, 3, 'e', '1a'] if secoes == 'all' else secoes\n",
    "    secoes = secoes if type(secoes) == list else [secoes]\n",
    "    secoes = [str(s) for s in secoes]\n",
    "    \n",
    "    # LOOP over dates:\n",
    "    url_file_list = []\n",
    "    Narticles_in_section = dict(zip(secoes, [0]*len(secoes)))\n",
    "    start_date = end_date + timedelta\n",
    "    if debug:\n",
    "        print('Will enter loop over config date and section range:')    \n",
    "    for date in daterange(start_date, end_date + dt.timedelta(days=1)):\n",
    "        if debug:\n",
    "            print('-- '+date.strftime('%Y-%m-%d'))\n",
    "        # LOOP over DOU sections:\n",
    "        for s in secoes:\n",
    "            if debug:\n",
    "                print('   -- s'+str(s))\n",
    "            jsons = get_artigos_do(date, s)\n",
    "            Narticles_in_section[s] = len(jsons)\n",
    "            # LOOP over downloaded URL list:\n",
    "            if debug:\n",
    "                print('      Looping over URLs...')            \n",
    "            for j in jsons:\n",
    "                url      = url_prefix + j['urlTitle']\n",
    "                filename = date.strftime('%Y-%m-%d') + '_s' + str(s) + '_' + fix_filename(j['urlTitle']) + '.json'\n",
    "                url_file_list.append({'url':url, 'filename':filename})\n",
    "        \n",
    "    if debug:\n",
    "        print('Narticles_in_section:', Narticles_in_section)\n",
    "    \n",
    "    if config['update_config']:\n",
    "        next_config = update_config(config, Narticles_in_section)\n",
    "    else:\n",
    "        next_config = config\n",
    "        \n",
    "    return url_file_list, next_config\n",
    "\n",
    "\n",
    "def entrypoint(params):\n",
    "    \"\"\"\n",
    "    Input:   params (dict)\n",
    "             Com as keywords 'dynamo_table' e 'config_key'\n",
    "    Retorna: lista de dicts com url e path\n",
    "    \n",
    "    Atualiza a config no dynamoDB\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load config from dynamoDB:\n",
    "    if params['use_config']:\n",
    "        config = load_remote_config(params['dynamo_table'], params['config_key'])\n",
    "        config['update_config'] = True\n",
    "    # Or use directly supplied parameters:\n",
    "    else:\n",
    "        config = params\n",
    "        config['update_config'] = False\n",
    "    # Get list of articles to download and update config:\n",
    "    url_file_list, next_config = get_articles_url(config)\n",
    "    \n",
    "    # Save config to AWS DynamoDB:\n",
    "    if params['use_config']:\n",
    "        client = boto3.client('dynamodb')\n",
    "        response = client.put_item(TableName=params['dynamo_table'], Item=dyjson.dumps(next_config, as_dict=True))\n",
    "    \n",
    "    return url_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['use_config'] = True\n",
    "params['dynamo_table'] = \"configs\"\n",
    "params['config_key']   = {\"name\": {\"S\": \"build_DOU_database\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"use_config\": False,\n",
    "    \"date_format\": \"%Y-%m-%d\",\n",
    "    \"debug\": False,\n",
    "    \"end_date\": \"2019-04-18\",\n",
    "    \"post_articles\": False,\n",
    "    \"save_articles\": True,\n",
    "    \"secao\": [1, 2, 3, \"e\"],\n",
    "    \"secao_all\": [1, 2, 3, \"e\"],\n",
    "    \"timedelta\": -2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting get_articles_url with config:\n",
      "{'use_config': False, 'date_format': '%Y-%m-%d', 'debug': False, 'end_date': '2019-04-18', 'post_articles': False, 'save_articles': True, 'secao': [1, 2, 3, 'e'], 'secao_all': [1, 2, 3, 'e'], 'timedelta': -2, 'update_config': False}\n",
      "Reading date range...\n",
      "Reading selected sections...\n",
      "Will enter loop over config date and section range:\n",
      "-- 2019-04-16\n",
      "   -- s1\n",
      "      Looping over URLs...\n",
      "   -- s2\n",
      "      Looping over URLs...\n",
      "   -- s3\n",
      "      Looping over URLs...\n",
      "   -- se\n",
      "      Looping over URLs...\n",
      "-- 2019-04-17\n",
      "   -- s1\n",
      "      Looping over URLs...\n",
      "   -- s2\n",
      "      Looping over URLs...\n",
      "   -- s3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-46f34524fb4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-1bae8f4c37c0>\u001b[0m in \u001b[0;36mentrypoint\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update_config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Get list of articles to download and update config:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0murl_file_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_articles_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# Save config to AWS DynamoDB:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1bae8f4c37c0>\u001b[0m in \u001b[0;36mget_articles_url\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'   -- s'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mjsons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_artigos_do\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mNarticles_in_section\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# LOOP over downloaded URL list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ce99745cdcea>\u001b[0m in \u001b[0;36mget_artigos_do\u001b[0;34m(data, secao)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mtree\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mxpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'//*[@id=\"params\"]/text()'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jsonArray'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfix_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlTitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "l = entrypoint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18873"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_parallel_batches(body, n_batches):\n",
    "    \"\"\"\n",
    "    Given a list `body` and an integer `n_batches`, tries to split `body` \n",
    "    into `n_batches` sub-lists. For certain combinations of parameters, \n",
    "    the number of sub-lists is different than the requested number `n_batches`.\n",
    "    It is recommended to measure the length of the returned list of batches.\n",
    "    \"\"\"\n",
    "    n_requests = len(body)\n",
    "    \n",
    "    # Set batch sizes:\n",
    "    batch_sizes = [round(n_requests / n_batches) for i in range(n_batches)]\n",
    "    batch_sizes[0] = max(n_requests - sum(batch_sizes[1:]), 0)\n",
    "\n",
    "    # Set positions that mark the start and end of batches:\n",
    "    batch_pos = [sum(batch_sizes[:i]) for i in range(n_batches + 1)]\n",
    "    \n",
    "    # Split into batches\n",
    "    batches = [body[batch_pos[i]:batch_pos[i+1]] for i in range(n_batches) \\\n",
    "               if len(body[batch_pos[i]:batch_pos[i+1]]) > 0]\n",
    "    \n",
    "    return batches    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_parallel_batches([], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
