{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## http-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from dynamodb_json import json_util as dyjson \n",
    "from pyathena import connect\n",
    "from datetime import timedelta, date, datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import google.auth\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "sys.path.insert(0, \"external_modules\")\n",
    "import importlib\n",
    "\n",
    "# Switch for printing messages to log:\n",
    "debug = False\n",
    "# Wheter this code is ran locally or on AWS:\n",
    "local = False\n",
    "\n",
    "\n",
    "def query_bigquery(query):\n",
    "    \"\"\"\n",
    "    Runs a `query` (str) on Google BigQuery and returns the results as\n",
    "    a list of dictionaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    if local:\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/tmp/key.json'\n",
    "    \n",
    "    # Get key for accessing BigQuery:\n",
    "    s3 = boto3.client('s3')\n",
    "    a  = s3.get_object(\n",
    "                  Bucket='config-lambda', \n",
    "                  Key='layers/google-cloud-storage/gabinete-compartilhado.json')\n",
    "    open('/tmp/key.json', 'w').write(a['Body'].read().decode('utf-8'))\n",
    "\n",
    "    # Create credentials with Drive & BigQuery API scopes\n",
    "    # Both APIs must be enabled for your project before running this code\n",
    "    credentials, project = google.auth.default(scopes=[\n",
    "        'https://www.googleapis.com/auth/drive',\n",
    "        'https://www.googleapis.com/auth/bigquery',\n",
    "    ])\n",
    "    bq = bigquery.Client(credentials=credentials, project=project)\n",
    "        \n",
    "    result = bq.query(\n",
    "        query,\n",
    "        # Location must match that of the dataset(s) referenced in the query.\n",
    "        location=\"US\",\n",
    "    )  # API request - starts the query\n",
    "    \n",
    "    result = [dict(r.items()) for r in result] \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def forms_bigquery(par, item, forms):\n",
    "    \"\"\"\n",
    "    Faz um query no Google BigQuery e usa os resultados para \n",
    "    construir uma lista de URLs e filenames (destino).\n",
    "    \"\"\"\n",
    "       \n",
    "    # Substitui parâmetros de input na query:\n",
    "    query = par['query'] % par['query_config']\n",
    "    \n",
    "    # Executa a query:\n",
    "    data = query_bigquery(query)\n",
    "        \n",
    "    # LOOP sobre as linhas do retorno do SQL:\n",
    "    for d in data:\n",
    "        \n",
    "        # Create data destination filename:\n",
    "        if len(d) > 1:\n",
    "            end_filename = '&'.join(map(lambda x: '='.join(map(str, x)), zip(par['url_params'], list(d.values()))))\n",
    "        else:\n",
    "            end_filename = d.values()[0]\n",
    "        filename = '_'.join(map(str, [item['name'], end_filename])) + '.json'\n",
    "        \n",
    "        # Create source url:    \n",
    "        url = item['url'] % dict(zip(par['url_params'], list(d.values())))\n",
    "        \n",
    "        if 'url' in d:\n",
    "            raise Exception(\"'url' key already exists in data; avoiding its redefinition.\")\n",
    "        if 'filename' in d:\n",
    "            raise Exception(\"'filename' key already exists in data; avoiding its redefinition.\")\n",
    "        d['url']      = url\n",
    "        d['filename'] = filename\n",
    "        \n",
    "        forms.append(d)\n",
    "    \n",
    "    return forms\n",
    "\n",
    "\n",
    "def forms_athena_query(par, item, forms):\n",
    "    \"\"\"\n",
    "    Faz um query no Athena (SQL da Amazon) e usa os resultados para \n",
    "    construir uma lista de URLs e filenames (destino).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get AWS security credentials:\n",
    "    client = boto3.client('s3')\n",
    "    a = client.get_object(Bucket='config-lambda', Key='aws_accessKeys.json')\n",
    "    aws_key = json.loads(a['Body'].read().decode('utf-8'))\n",
    "\n",
    "    # Conecta à Athena com pacote do Joe.\n",
    "    cursor = connect(aws_access_key_id=aws_key['aws_access_key_id'],\n",
    "                         aws_secret_access_key=aws_key['aws_secret_access_key'],\n",
    "                         s3_staging_dir='s3://stagging-random/',\n",
    "                         region_name='us-east-1').cursor()\n",
    "    \n",
    "    # Substitui parâmetros de input na query:\n",
    "    query = par['query'] % par['query_config']\n",
    "    \n",
    "    # Executa a query:\n",
    "    data = cursor.execute(query).fetchall() \n",
    "    \n",
    "    # LOOP sobre as linhas do retorno do SQL:\n",
    "    for d in data:\n",
    "        \n",
    "        if len(d) > 1:\n",
    "            end_filename = '&'.join(map(lambda x: '='.join(map(str, x)),\n",
    "                                                  zip(par['url_params'], \n",
    "                                                      list(d))))\n",
    "        else:\n",
    "            end_filename = d[0]\n",
    "\n",
    "        forms.append({'url': item['url'] % dict(zip(par['url_params'], list(d))),\n",
    "                      'filename': '_'.join(map(str, [item['name'], end_filename])) + '.json'\n",
    "                      })\n",
    "    \n",
    "    return forms\n",
    "\n",
    "\n",
    "def forms_from_to(par, item, forms):\n",
    "    \"\"\"\n",
    "    A partir de um modelo de URL e de filename, cria realizações concretas \n",
    "    substituindo cada um dos anos listados como input nos URLs e filenames.\n",
    "    \n",
    "    Dynamodb data structure:\n",
    "    {\n",
    "      \"body\": {\n",
    "        \"from\": 1993,\n",
    "        \"to\": 2019\n",
    "      },\n",
    "      \"name\": \"id\",\n",
    "      \"type\": \"from_to\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # LOOP sobre os anos:\n",
    "    for year in range(par['body']['from'], par['body']['to'] + 1):\n",
    "        \n",
    "        forms.append({'url': item['url'] % {par['name']: year},\n",
    "                      'filename': '_'.join(map(str, [item['name'], year])) + '.json'\n",
    "                      })\n",
    "    \n",
    "    return forms\n",
    "   \n",
    "    \n",
    "def forms_from_external_list(par, item, forms, event):\n",
    "    \n",
    "    for item_from_list in event['external_params']['list']:\n",
    "        \n",
    "        forms.append({'url': item['url'] % {par['url_param']: item_from_list},\n",
    "                      'filename': '_'.join(map(str, [item['name'], item_from_list])) + '.json'\n",
    "                      })\n",
    "    \n",
    "    return forms\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Given a 'start_date' and an 'end_date' (datetimes), returns a generator\n",
    "    for dates in that range, with the same behaviour as 'range' (i.e. excludes \n",
    "    the 'end_date' from the returned values).\n",
    "    \n",
    "    NOTE: if 'start_date' > 'end_date', it returns the dates from 'end_date' \n",
    "    to 'start_date', excluding 'start_date' instead of 'end_date'. In other\n",
    "    words, it always excludes the farthest future date.\n",
    "    \"\"\"\n",
    "    if end_date - start_date < timedelta(0):\n",
    "        temp_date  = end_date\n",
    "        end_date   = start_date\n",
    "        start_date = temp_date\n",
    "    \n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "\n",
    "def forms_date_start_end(par, item, forms):\n",
    "    \"\"\"\n",
    "    A partir de um modelo de URL e de filename, cria realizações concretas \n",
    "    substituindo cada um das datas listadas como input nos URLs e filenames.\n",
    "    As datas tem formato definido por date_format que vem no input.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse relative or specified capture's end date: \n",
    "    if par['end_date'] == 'yesterday':\n",
    "        end_date = date.today() - timedelta(1)\n",
    "    elif par['end_date'] == 'now':\n",
    "        end_date = date.today()\n",
    "    else:\n",
    "        end_date = datetime.strptime(par['end_date'], par['date_format'])\n",
    "\n",
    "    start_date = end_date + timedelta(par['timedelta'])\n",
    "    \n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        dates = {'start_date': single_date, 'end_date': single_date + timedelta(1)}\n",
    "        \n",
    "        # Create filename for data:\n",
    "        # In case both dates are required in the url:\n",
    "        if (item['url'].find('start_date') != -1) and (item['url'].find('end_date') != -1):\n",
    "            filename = '_'.join([item['name'],\n",
    "                                          datetime.strftime(dates['start_date'], '%Y-%m-%d'),\n",
    "                                          datetime.strftime(dates['end_date'], '%Y-%m-%d'),]) + '.json'\n",
    "        # In case only the start date is required in the url:\n",
    "        elif item['url'].find('start_date') != -1:\n",
    "            filename = '_'.join([item['name'], datetime.strftime(dates['start_date'], '%Y-%m-%d')]) + '.json'\n",
    "        # In case only the end date is required in the url:\n",
    "        elif item['url'].find('end_date') != -1:\n",
    "            filename = '_'.join([item['name'], datetime.strftime(dates['end_date'], '%Y-%m-%d')]) + '.json'\n",
    "        # In case no dates are required in the URL:\n",
    "        else:\n",
    "            filename = item['name'] + '.json'\n",
    "\n",
    "        forms.append({'url': item['url'] % {key: datetime.strftime(value, par['date_format']) for key, value in dates.items()},\n",
    "            'filename': filename})\n",
    "    \n",
    "    return forms\n",
    "\n",
    "\n",
    "def forms_external_module(par, item, forms):\n",
    "    \n",
    "    em = importlib.import_module(item['name'].replace('-', '_'))\n",
    "    \n",
    "    return em.entrypoint(par)\n",
    "\n",
    "\n",
    "def generate_forms(item, event):\n",
    "    \"\"\"\n",
    "    Cria URLs a partir das informações no dynamo.\n",
    "    \n",
    "    Retorno: forms, que é basicamente uma lista de dicionários que \n",
    "    cada dicionário contém um URL e uma filename (destino).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pega entrada 'parameters' no arquivo do dynamo:\n",
    "    parameters = item['parameters']\n",
    "    \n",
    "    forms = []\n",
    "    for par in parameters:\n",
    "        print(par)\n",
    "        \n",
    "        # Verifica o tipo de tarefa e executa o código apropriado:\n",
    "        if par['type'] == 'from_to':\n",
    "            \n",
    "            forms = forms_from_to(par, item, forms)\n",
    "\n",
    "        elif par['type'] == 'date_start_end':\n",
    "\n",
    "            forms = forms_date_start_end(par, item, forms)\n",
    "        \n",
    "        elif par['type'] == 'athena_query':\n",
    "\n",
    "            forms = forms_athena_query(par, item, forms)\n",
    "        \n",
    "        elif par['type'] == 'bigquery':\n",
    "            forms = forms_bigquery(par, item, forms)\n",
    "            \n",
    "        elif par['type'] == 'external_list':\n",
    "            \n",
    "            form = forms_from_external_list(par, item, forms, event)\n",
    "        \n",
    "        elif par['type'] == 'empty':\n",
    "            \n",
    "            forms = [{'url': item['url'],\n",
    "                      'filename': item['name'] + '.json'\n",
    "                     }]\n",
    "        \n",
    "        elif par['type'] == 'external_module':\n",
    "            forms = forms_external_module(par['params'], item, forms)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            raise 'Parameter type not identified'\n",
    "            \n",
    "    return forms \n",
    "    \n",
    "    \n",
    "def generate_body(response, event):\n",
    "    \"\"\"\n",
    "    Gera as URLs a partir de informações em arquivo 'response' do dynamo,\n",
    "    e outras coisas (metadados necessários).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gera as URLs:\n",
    "    forms = generate_forms(response['Item'], event)\n",
    "    \n",
    "    # O response item é um dicionário. Aqui incluímos o default para \n",
    "    # não dar pau se faltar alguma key do dicionário (e.g. records_keys)\n",
    "    response['Item'] = defaultdict(lambda: None, response['Item'])\n",
    "\n",
    "    # Vamos popular uma lista de dicionários 'body' com URLs e metadados:    \n",
    "    body = []\n",
    "    for item in forms:\n",
    "    # Do item vem filename e url, o resto vem do dynamo, basicamente infos \n",
    "    # sobre localização dos dados.\n",
    "    \n",
    "        request_pars = dict(url=item.pop('url'),\n",
    "                            params={},\n",
    "                            headers=response['Item']['headers'],\n",
    "                            bucket=response['Item']['bucket'],\n",
    "                            key=response['Item']['key'] + item.pop('filename'),\n",
    "                            data_type=response['Item']['data_type'],\n",
    "                            data_path=response['Item']['data_path'],\n",
    "                            exclude_keys=response['Item']['exclude_keys'],\n",
    "                            records_keys=response['Item']['records_keys'],\n",
    "                            name=response['Item']['name']\n",
    "                           )\n",
    "        request_pars['aux_data'] = item\n",
    "    \n",
    "        body.append(request_pars)\n",
    "        \n",
    "    return body\n",
    "    \n",
    "\n",
    "def create_dynamo_temp_table(table_name, dynamodb):\n",
    "    \n",
    "    try:\n",
    "        table = dynamodb.Table(table_name)\n",
    "        table.table_status\n",
    "\n",
    "    except:\n",
    "        create_table_response = dynamodb.create_table(\n",
    "            TableName= table_name,\n",
    "            AttributeDefinitions=[{\n",
    "            'AttributeName': 'order',\n",
    "            'AttributeType': 'N'\n",
    "            }],\n",
    "            KeySchema=[{\n",
    "                'AttributeName': 'order',\n",
    "                'KeyType': 'HASH'\n",
    "            }],\n",
    "            BillingMode='PAY_PER_REQUEST'\n",
    "        )\n",
    "    \n",
    "    \n",
    "def create_and_populate_dynamodb_table(urls, event):\n",
    "    \"\"\"\n",
    "    urls é uma lista de dicionários. Cada dicionário tem \n",
    "    entradas descritas em 'body' na função generate forms acima.\n",
    "    \"\"\"\n",
    "    \n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "   \n",
    "    # Determina o nome da tabela de output no dynamo a partir das informações de captura: \n",
    "    table_name = '-'.join(['temp-capture',\n",
    "                            event['key']['name']['S'],\n",
    "                            event['key']['capture_type']['S'],\n",
    "                            datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M-%S')])\n",
    "    \n",
    "    # Cria uma tabela vazia no dynamo:\n",
    "    create_dynamo_temp_table(table_name, dynamodb)\n",
    "\n",
    "    time.sleep(60)\n",
    "    \n",
    "    # Pega a referência (pointer) da tabela do dynamo:    \n",
    "    table = dynamodb.Table(table_name)\n",
    "\n",
    "    # Escreve os dicionários criados pela função generate_body na tabela do dynamo: \n",
    "    # REAAALY FAST!\n",
    "    with table.batch_writer() as batch:\n",
    "        for order, url in enumerate(urls): \n",
    "            url.update({'order': order})   # Cria um novo key com a ordem dos dicionários 'url' na lista 'urls'.\n",
    "            batch.put_item(Item=url)\n",
    "\n",
    "    # Retorna o nome da tabela e o número de linhas - 1:    \n",
    "    return {'dynamo_table_name': table_name, 'order': len(urls) - 1}\n",
    "\n",
    "\n",
    "def adapt_url_key(body_entry):\n",
    "    \"\"\"\n",
    "    Rename the `body_entry` dict key 'url' to 'identifier' \n",
    "    if its value does not start with 'http' or 'ftp'.\n",
    "    \n",
    "    PS: It changes the content of the input dict `body_entry`.\n",
    "    \"\"\"\n",
    "    \n",
    "    adapted = body_entry\n",
    "    if body_entry['url'][:4] != 'http' and body_entry['url'][:3] != 'ftp':\n",
    "        body_entry['identifier'] = body_entry.pop('url')\n",
    "    \n",
    "    return body_entry\n",
    "\n",
    "\n",
    "def read_parallel_batches(response):\n",
    "    \"\"\"\n",
    "    Given a `response` from dynamoDB's get_item (after translating from dyJSON, \n",
    "    that is, a dict where the important information, the content of a table's item, \n",
    "    is inside the key 'Item'), return the number of parallel batches in which to \n",
    "    split the requests. This is 1 by default, or something else if specified in the \n",
    "    dynamoDB item.\n",
    "    \"\"\"\n",
    "    \n",
    "    parallel_key = 'parallel_batches'\n",
    "    config = response['Item']\n",
    "    \n",
    "    if parallel_key not in config.keys() or config[parallel_key] == None or config[parallel_key] <= 1:\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return config[parallel_key]\n",
    "\n",
    "\n",
    "def split_parallel_batches(body, n_batches):\n",
    "    \"\"\"\n",
    "    Given a list `body` and an integer `n_batches`, tries to split `body` \n",
    "    into `n_batches` sub-lists. For certain combinations of parameters, \n",
    "    the number of sub-lists is different than the requested number `n_batches`.\n",
    "    It is recommended to measure the length of the returned list of batches.\n",
    "    \"\"\"\n",
    "    n_requests = len(body)\n",
    "    \n",
    "    # Set batch sizes:\n",
    "    batch_sizes = [round(n_requests / n_batches) for i in range(n_batches)]\n",
    "    batch_sizes[0] = max(n_requests - sum(batch_sizes[1:]), 0)\n",
    "\n",
    "    # Set positions that mark the start and end of batches:\n",
    "    batch_pos = [sum(batch_sizes[:i]) for i in range(n_batches + 1)]\n",
    "    \n",
    "    # Split into batches\n",
    "    batches = [body[batch_pos[i]:batch_pos[i+1]] for i in range(n_batches) \\\n",
    "               if len(body[batch_pos[i]:batch_pos[i+1]]) > 0]\n",
    "    \n",
    "    return batches    \n",
    "    \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Cria lista de de URLs para baixar, e depois chama o lambd.invoke que \n",
    "    efetivamente baixa o conteúdo dos URLs.\n",
    "    \n",
    "    # Exemplo de input em `event`:\n",
    "    {\n",
    "      \"table_name\": \"capture_urls\",\n",
    "      \"key\": {\n",
    "        \"name\": {\n",
    "          \"S\": \"camara-deputados-detalhes\"\n",
    "        },\n",
    "        \"capture_type\": {\n",
    "          \"S\": \"historical\"\n",
    "        }\n",
    "      }\n",
    "    }\"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"Starting parametrize-API-requests with event:\")\n",
    "    print(event)\n",
    "\n",
    "    # Cria cliente do dynamo:\n",
    "    client = boto3.client('dynamodb')\n",
    "\n",
    "    # Seleciona um arquivo do dynamo:\n",
    "    response = client.get_item(TableName=event['table_name'], \n",
    "                                Key=event['key'])\n",
    "\n",
    "    # Lê o arquivo do dynamo (retorna uma lista de dicionários ou um dicionário):\n",
    "    response = dyjson.loads(response)\n",
    "    if debug == True:\n",
    "        print(\"dict of dynamo Table:\") \n",
    "        print(response)\n",
    "\n",
    "    # Gera as URLs e os filenames (destino):\n",
    "    body = generate_body(response, event)\n",
    "    # Rename 'url' key if it is not an url:\n",
    "    body = [adapt_url_key(b) for b in body]\n",
    "\n",
    "    # Split requests in parallel batches according to config:\n",
    "    n_batches = read_parallel_batches(response)\n",
    "    body_batches = split_parallel_batches(body, n_batches)\n",
    "\n",
    "    # Chama cliente do lambda:\n",
    "    lambd = boto3.client('lambda')\n",
    "\n",
    "    for body in body_batches:\n",
    "        print('Create dynamo temp table with', len(body), 'entries')\n",
    "\n",
    "        # Salva os as informações geradas acima no dynamo como uma tabela temp:\n",
    "        params = create_and_populate_dynamodb_table(body, event)\n",
    "        if debug == True:\n",
    "            print('URLs to capture listed in:')\n",
    "            print(params)\n",
    "\n",
    "        # Faz a captura efetivamente, com os parâmetros criados por generate_body e \n",
    "        # salvos por create_and_populate_dynamodb_table:    \n",
    "        if True:\n",
    "            if debug:\n",
    "                print('Invoking http-request...')\n",
    "            lambd.invoke(\n",
    "                FunctionName='arn:aws:lambda:us-east-1:085250262607:function:http-request:JustLambda',\n",
    "                #FunctionName='arn:aws:lambda:us-east-1:085250262607:function:http-request:DEV',\n",
    "                InvocationType='Event',\n",
    "                Payload=json.dumps(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "  \"table_name\": \"capture_urls\",\n",
    "  \"key\": {\n",
    "    \"name\": {\n",
    "      \"S\": \"camara-deputados-detalhes\"\n",
    "    },\n",
    "    \"capture_type\": {\n",
    "      \"S\": \"daily\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parametrize-API-requests with event:\n",
      "{'table_name': 'capture_urls', 'key': {'name': {'S': 'camara-deputados-detalhes'}, 'capture_type': {'S': 'daily'}}}\n",
      "dict of dynamo Table:\n",
      "{'Item': {'parameters': [{'query_config': {}, 'url_params': ['id'], 'type': 'athena_query', 'query': \"SELECT split(uri, '/')[7] FROM camara_v2.deputados WHERE idlegislaturafinal = 56\"}], 'data_path': ['dados'], 'capture_type': 'daily', 'bucket': 'brutos-publicos', 'key': 'legislativo/camara/v2/deputados-detalhes/', 'url': 'https://dadosabertos.camara.leg.br/api/v2/deputados/%(id)s', 'headers': {}, 'name': 'camara-deputados-detalhes', 'data_type': 'json'}, 'ResponseMetadata': {'RequestId': '7713CHMH3FEL59B397F45GN91FVV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Thu, 26 Mar 2020 20:18:45 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '530', 'connection': 'keep-alive', 'x-amzn-requestid': '7713CHMH3FEL59B397F45GN91FVV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '2619334475'}, 'RetryAttempts': 0}}\n",
      "{'query_config': {}, 'url_params': ['id'], 'type': 'athena_query', 'query': \"SELECT split(uri, '/')[7] FROM camara_v2.deputados WHERE idlegislaturafinal = 56\"}\n",
      "Create dynamo temp table with 548 entries\n",
      "URLs to capture listed in:\n",
      "Invoking http-request...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting parametrize-API-requests with event:\")\n",
    "print(event)\n",
    "\n",
    "# Cria cliente do dynamo:\n",
    "client = boto3.client('dynamodb')\n",
    "\n",
    "# Seleciona um arquivo do dynamo:\n",
    "response = client.get_item(TableName=event['table_name'], \n",
    "                            Key=event['key'])\n",
    "\n",
    "# Lê o arquivo do dynamo (retorna uma lista de dicionários ou um dicionário):\n",
    "response = dyjson.loads(response)\n",
    "if debug == True:\n",
    "    print(\"dict of dynamo Table:\") \n",
    "    print(response)\n",
    "\n",
    "# Gera as URLs e os filenames (destino):\n",
    "body = generate_body(response, event)\n",
    "# Rename 'url' key if it is not an url:\n",
    "body = [adapt_url_key(b) for b in body]\n",
    "\n",
    "# Split requests in parallel batches according to config:\n",
    "n_batches = read_parallel_batches(response)\n",
    "body_batches = split_parallel_batches(body, n_batches)\n",
    "\n",
    "# Chama cliente do lambda:\n",
    "lambd = boto3.client('lambda')\n",
    "\n",
    "for body in body_batches:\n",
    "    print('Create dynamo temp table with', len(body), 'entries')\n",
    "    \n",
    "    # Salva os as informações geradas acima no dynamo como uma tabela temp:\n",
    "    params = create_and_populate_dynamodb_table(body, event)\n",
    "    if debug == True:\n",
    "        print('URLs to capture listed in:')\n",
    "        print(params)\n",
    "        \n",
    "    # Faz a captura efetivamente, com os parâmetros criados por generate_body e \n",
    "    # salvos por create_and_populate_dynamodb_table:    \n",
    "    if True:\n",
    "        if debug:\n",
    "            print('Invoking http-request...')\n",
    "        lambd.invoke(\n",
    "            FunctionName='arn:aws:lambda:us-east-1:085250262607:function:http-request:JustLambda',\n",
    "            #FunctionName='arn:aws:lambda:us-east-1:085250262607:function:http-request:DEV',\n",
    "            InvocationType='Event',\n",
    "            Payload=json.dumps(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_index_sets(body, n_batches):\n",
    "    n_requests = len(body)\n",
    "    \n",
    "    # Determine the sizes of the batches:\n",
    "    batch_sizes = [round(n_requests / n_batches) for i in range(n_batches)]\n",
    "    batch_sizes[0] = n_requests - sum(batch_sizes[1:])\n",
    "\n",
    "    for i in range(0, len(set_fracs) - 1):\n",
    "        # Select indices for a set:\n",
    "        set_start.append(set_start[i] + set_sizes[i])\n",
    "        set_indices = shuffled_indices[set_start[i]:set_start[i + 1]]\n",
    "        indices.append(set_indices)\n",
    "        assert len(indices[i]) == len(set(indices[i])), 'There are repeating indices in a set.'\n",
    "        \n",
    "    # Select the indices for the last set:\n",
    "    indices.append(shuffled_indices[set_start[-1]:])\n",
    "    assert len(set(np.concatenate(indices))) == sum([len(i) for i in indices]), \\\n",
    "    'There are common indices between sets.'\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
